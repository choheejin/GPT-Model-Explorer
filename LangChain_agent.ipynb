{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tdNUh5W63Il",
        "outputId": "a08b92db-beb1-405b-ae17-d93401953c69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.7-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Collecting aiohttp (from openai)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m58.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->openai)\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->openai)\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp->openai)\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->openai)\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp->openai)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Installing collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, openai\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.7 yarl-1.9.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.0.191-py3-none-any.whl (993 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m993.7/993.7 kB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.10)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.8.4)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.2)\n",
            "Collecting dataclasses-json<0.6.0,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.5.7-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.4)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.22.4)\n",
            "Collecting openapi-schema-pydantic<2.0,>=1.2 (from langchain)\n",
            "  Downloading openapi_schema_pydantic-1.2.4-py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.7)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.27.1)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Collecting marshmallow<4.0.0,>=3.3.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.19.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting marshmallow-enum<2.0.0,>=1.5.1 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading marshmallow_enum-1.5.1-py2.py3-none-any.whl (4.2 kB)\n",
            "Collecting typing-inspect>=0.4.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2,>=1->langchain) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, openapi-schema-pydantic, marshmallow-enum, dataclasses-json, langchain\n",
            "Successfully installed dataclasses-json-0.5.7 langchain-0.0.191 marshmallow-3.19.0 marshmallow-enum-1.5.1 mypy-extensions-1.0.0 openapi-schema-pydantic-1.2.4 typing-inspect-0.9.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting google-search-results\n",
            "  Downloading google_search_results-2.4.2.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from google-search-results) (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (3.4)\n",
            "Building wheels for collected packages: google-search-results\n",
            "  Building wheel for google-search-results (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for google-search-results: filename=google_search_results-2.4.2-py3-none-any.whl size=32002 sha256=3a02aeec5e724c89228a5e33a5d6b44a2a7e78534b74eaceb03aefa37f3f5e1e\n",
            "  Stored in directory: /root/.cache/pip/wheels/d3/b2/c3/03302d12bb44a2cdff3c9371f31b72c0c4e84b8d2285eeac53\n",
            "Successfully built google-search-results\n",
            "Installing collected packages: google-search-results\n",
            "Successfully installed google-search-results-2.4.2\n"
          ]
        }
      ],
      "source": [
        "!pip install openai\n",
        "!pip install langchain\n",
        "!pip install google-search-results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lT8WVV566rCs"
      },
      "outputs": [],
      "source": [
        "from langchain import OpenAI\n",
        "\n",
        "from langchain.agents import load_tools\n",
        "from langchain.agents import initialize_agent\n",
        "from langchain.agents import AgentType\n",
        "\n",
        "from langchain.utilities import SerpAPIWrapper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EH7P6_vd7Kh7"
      },
      "outputs": [],
      "source": [
        "## 사용자키 설정\n",
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"sk-##\"\n",
        "os.environ[\"SERPAPI_API_KEY\"] = \"##\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ztPg2I7x6t2V"
      },
      "outputs": [],
      "source": [
        "# 사용할 언어 모델 설정\n",
        "llm = OpenAI(temperature=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E0k90b8j7VQo"
      },
      "outputs": [],
      "source": [
        "# 사용할 도구 설정\n",
        "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UXZFQMim9TF-"
      },
      "outputs": [],
      "source": [
        "# 에이전트 선언\n",
        "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "id": "rotGVeH4IEP0",
        "outputId": "27b8b576-bb6e-4b18-a343-8735df30cddf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m 대한민국의 대통령을 찾고 그 나이를 계산해야 한다.\n",
            "Action: Search\n",
            "Action Input: 대한민국 대통령 2023\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mYoon Suk Yeol is a South Korean politician who has been serving as the 13th and current president of South Korea since 2022. Prior to his presidency, he served as the prosecutor general of South Korea between 2019 and 2021. Born in Seoul, Yoon attended Seoul National University.\u001b[0m\n",
            "Thought:"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:langchain.llms.openai:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f231d34221f4e3d7df6381ea23429600 in your message.).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32;1m\u001b[1;3m Yoon Suk Yeol의 생년월일을 찾아야 한다.\n",
            "Action: Search\n",
            "Action Input: Yoon Suk Yeol 생년월일\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mDecember 18, 1960\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m Yoon Suk Yeol의 나이를 계산해야 한다.\n",
            "Action: Calculator\n",
            "Action Input: 2023 - 1960\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3mAnswer: 63\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
            "Final Answer: Yoon Suk Yeol은 2023년 기준으로 63세이다.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Yoon Suk Yeol은 2023년 기준으로 63세이다.'"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 에이전트 실행\n",
        "agent.run(\"대한민국의 대통령을 2023년 기준으로 대한민국의 대통령이 누군지 찾아라. 해당 대통령의 현재 (2023년) 나이를 계산해라.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpWoaO6skN1b",
        "outputId": "fa299702-69f7-40d1-a56f-4ab97aaf980c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "name='Search' description='A search engine. Useful for when you need to answer questions about current events. Input should be a search query.' args_schema=None return_direct=False verbose=False callbacks=None callback_manager=None handle_tool_error=False func=<bound method SerpAPIWrapper.run of SerpAPIWrapper(search_engine=<class 'serpapi.google_search.GoogleSearch'>, params={'engine': 'google', 'google_domain': 'google.com', 'gl': 'us', 'hl': 'en'}, serpapi_api_key='43d7ab687676d6de83bfbd031578c8c4496e39f73012094ae129bfd8b6887e95', aiosession=None)> coroutine=<bound method SerpAPIWrapper.arun of SerpAPIWrapper(search_engine=<class 'serpapi.google_search.GoogleSearch'>, params={'engine': 'google', 'google_domain': 'google.com', 'gl': 'us', 'hl': 'en'}, serpapi_api_key='43d7ab687676d6de83bfbd031578c8c4496e39f73012094ae129bfd8b6887e95', aiosession=None)>\n"
          ]
        }
      ],
      "source": [
        "print(agent.tools[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RM-vpXKnny1Q"
      },
      "outputs": [],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.experimental.plan_and_execute import PlanAndExecute, load_agent_executor, load_chat_planner\n",
        "from langchain.llms import OpenAI\n",
        "from langchain import SerpAPIWrapper\n",
        "from langchain.agents.tools import Tool\n",
        "from langchain import LLMMathChain\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bChpGZnRn0tO"
      },
      "outputs": [],
      "source": [
        "search = SerpAPIWrapper()\n",
        "llm = OpenAI(temperature=0)\n",
        "llm_math_chain = LLMMathChain.from_llm(llm=llm, verbose=True)\n",
        "tools = [\n",
        "    Tool(\n",
        "        name = \"Search\",\n",
        "        func=search.run,\n",
        "        description=\"useful for when you need to answer questions about current events\"\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"Calculator\",\n",
        "        func=llm_math_chain.run,\n",
        "        description=\"useful for when you need to answer questions about math\"\n",
        "    ),\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fKOkL6wXn22u",
        "outputId": "54053d90-1974-4ffa-e1c0-4ed68d3ceb34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new PlanAndExecute chain...\u001b[0m\n",
            "steps=[Step(value='대한민국 대통령 목록을 찾아서 2023년 기준으로 누가 대통령인지 확인한다.'), Step(value='대통령의 생년월일을 찾아서 현재 나이를 계산한다.'), Step(value='계산된 현재 나이를 출력한다.\\n')]\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mAction:\n",
            "```\n",
            "{\n",
            "  \"action\": \"Search\",\n",
            "  \"action_input\": \"List of Presidents of South Korea as of 2023\"\n",
            "}\n",
            "```\n",
            "\n",
            "\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mYoon Suk Yeol is a South Korean politician who has been serving as the 13th and current president of South Korea since 2022. Prior to his presidency, he served as the prosecutor general of South Korea between 2019 and 2021. Born in Seoul, Yoon attended Seoul National University.\u001b[0m\n",
            "Thought:"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-ySXADTYxkv77kxJzfGrXW0be on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32;1m\u001b[1;3mThe human is looking for the current president of South Korea as of 2023. I have found that Yoon Suk Yeol is the current president of South Korea as of 2023. \n",
            "\n",
            "Action:\n",
            "```\n",
            "{\n",
            "  \"action\": \"Final Answer\",\n",
            "  \"action_input\": \"The current president of South Korea as of 2023 is Yoon Suk Yeol.\"\n",
            "}\n",
            "```\n",
            "\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "*****\n",
            "\n",
            "Step: 대한민국 대통령 목록을 찾아서 2023년 기준으로 누가 대통령인지 확인한다.\n",
            "\n",
            "Response: The current president of South Korea as of 2023 is Yoon Suk Yeol.\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-ySXADTYxkv77kxJzfGrXW0be on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-ySXADTYxkv77kxJzfGrXW0be on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-ySXADTYxkv77kxJzfGrXW0be on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 16.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-ySXADTYxkv77kxJzfGrXW0be on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32;1m\u001b[1;3mAction:\n",
            "```\n",
            "{\n",
            "  \"action\": \"Search\",\n",
            "  \"action_input\": \"What is the birthdate of Yoon Suk Yeol, the current president of South Korea?\"\n",
            "}\n",
            "```\n",
            "\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mYoon Suk Yeol (Korean: 윤석열; born 18 December 1960) is a South Korean politician who has been serving as the 13th and current president of South Korea ...\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mTo calculate the current age of Yoon Suk Yeol, I will need to get the current date and subtract his birthdate from it. \n",
            "\n",
            "Action:\n",
            "```\n",
            "{\n",
            "  \"action\": \"Calculator\",\n",
            "  \"action_input\": \"2023-12-18 - 1960-12-18\"\n",
            "}\n",
            "```\n",
            "\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Entering new LLMMathChain chain...\u001b[0m\n",
            "2023-12-18 - 1960-12-18"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-ySXADTYxkv77kxJzfGrXW0be on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32;1m\u001b[1;3m```text\n",
            "2023-1960\n",
            "```\n",
            "...numexpr.evaluate(\"2023-1960\")...\n",
            "\u001b[0m\n",
            "Answer: \u001b[33;1m\u001b[1;3m63\u001b[0m\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "Observation: \u001b[33;1m\u001b[1;3mAnswer: 63\u001b[0m\n",
            "Thought:"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-ySXADTYxkv77kxJzfGrXW0be on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-ySXADTYxkv77kxJzfGrXW0be on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-ySXADTYxkv77kxJzfGrXW0be on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 16.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-ySXADTYxkv77kxJzfGrXW0be on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-ySXADTYxkv77kxJzfGrXW0be on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32;1m\u001b[1;3mTo answer the human's question, I will provide the current age of Yoon Suk Yeol, which is 63.\n",
            "\n",
            "Action:\n",
            "```\n",
            "{\n",
            "  \"action\": \"Final Answer\",\n",
            "  \"action_input\": \"Yoon Suk Yeol's current age is 63.\"\n",
            "}\n",
            "```\n",
            "\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "*****\n",
            "\n",
            "Step: 대통령의 생년월일을 찾아서 현재 나이를 계산한다.\n",
            "\n",
            "Response: Yoon Suk Yeol's current age is 63.\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-ySXADTYxkv77kxJzfGrXW0be on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32;1m\u001b[1;3mAction:\n",
            "```\n",
            "{\n",
            "  \"action\": \"Final Answer\",\n",
            "  \"action_input\": \"Yoon Suk Yeol's current age is 63.\"\n",
            "}\n",
            "```\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "*****\n",
            "\n",
            "Step: 계산된 현재 나이를 출력한다.\n",
            "\n",
            "\n",
            "Response: Yoon Suk Yeol's current age is 63.\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Yoon Suk Yeol's current age is 63.\""
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 사용할 언어 모델 선택 \n",
        "model = ChatOpenAI(temperature=0)\n",
        "# 플래너 설정\n",
        "planner = load_chat_planner(model)\n",
        "# 실행자 설정\n",
        "executor = load_agent_executor(model, tools, verbose=True)\n",
        "# 에이전트 선언\n",
        "agent = PlanAndExecute(planner=planner, executor=executor, verbose=True)\n",
        "\n",
        "# 에이전트 실행\n",
        "agent.run(\"대한민국의 대통령을 2023년 기준으로 대한민국의 대통령이 누군지 찾아라. 대통령의 생년월일과 2023년를 비교하여 현재 나이를 계산해라.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rm4AHeWDjKRq"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import create_sql_agent\n",
        "from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
        "from langchain.sql_database import SQLDatabase\n",
        "from langchain.llms.openai import OpenAI\n",
        "from langchain.agents import AgentExecutor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGlpxijLjLl-",
        "outputId": "dab38d3c-b52b-4313-bae0-aafb1a0d85a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        },
        "id": "V6JFT2axjboB",
        "outputId": "3419b615-b1c0-4666-f3f0-ce6a6664829b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mAction: list_tables_sql_db\n",
            "Action Input: \"\"\u001b[0m\n",
            "Observation: \u001b[38;5;200m\u001b[1;3mcustomer, actor, inventory, film_actor, rental, film_text, address, film, category, store, staff, country, language, city, film_category, payment\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I should query the schema of the customer table\n",
            "Action: schema_sql_db\n",
            "Action Input: \"customer\"\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3m\n",
            "CREATE TABLE customer (\n",
            "\tcustomer_id INTEGER NOT NULL, \n",
            "\tstore_id INTEGER NOT NULL, \n",
            "\tfirst_name VARCHAR(45) NOT NULL, \n",
            "\tlast_name VARCHAR(45) NOT NULL, \n",
            "\temail VARCHAR(50) DEFAULT NULL, \n",
            "\taddress_id INTEGER NOT NULL, \n",
            "\tactive CHAR(1) DEFAULT 'Y' NOT NULL, \n",
            "\tcreate_date TIMESTAMP NOT NULL, \n",
            "\tlast_update TIMESTAMP NOT NULL, \n",
            "\tPRIMARY KEY (customer_id), \n",
            "\tCONSTRAINT fk_customer_store FOREIGN KEY(store_id) REFERENCES store (store_id) ON UPDATE CASCADE, \n",
            "\tCONSTRAINT fk_customer_address FOREIGN KEY(address_id) REFERENCES address (address_id) ON UPDATE CASCADE\n",
            ")\n",
            "\n",
            "/*\n",
            "3 rows from customer table:\n",
            "customer_id\tstore_id\tfirst_name\tlast_name\temail\taddress_id\tactive\tcreate_date\tlast_update\n",
            "1\t1\tMARY\tSMITH\tMARY.SMITH@sakilacustomer.org\t5\t1\t2006-02-14 22:04:36\t2021-03-06 15:53:36\n",
            "2\t1\tPATRICIA\tJOHNSON\tPATRICIA.JOHNSON@sakilacustomer.org\t6\t1\t2006-02-14 22:04:36\t2021-03-06 15:53:36\n",
            "3\t1\tLINDA\tWILLIAMS\tLINDA.WILLIAMS@sakilacustomer.org\t7\t1\t2006-02-14 22:04:36\t2021-03-06 15:53:36\n",
            "*/\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
            "Final Answer: customer 테이블은 customer_id, store_id, first_name, last_name, email, address_id, active, create_date, last_update 의 열을 가지고 있으며, 각 열은 각각 INTEGER, VARCHAR, CHAR, TIMESTAMP 타입을 가지고 있습니다.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'customer 테이블은 customer_id, store_id, first_name, last_name, email, address_id, active, create_date, last_update 의 열을 가지고 있으며, 각 열은 각각 INTEGER, VARCHAR, CHAR, TIMESTAMP 타입을 가지고 있습니다.'"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 불러올 데이터베이스 선택\n",
        "db = SQLDatabase.from_uri(\"sqlite:////content/drive/My Drive/Colab Notebooks/sqlite-sakila.db\")\n",
        "# 툴킷 선언\n",
        "toolkit = SQLDatabaseToolkit(db=db, llm=llm)\n",
        "# 에이전트 선언\n",
        "agent_executor = create_sql_agent(\n",
        "    llm=OpenAI(temperature=0),\n",
        "    toolkit=toolkit,\n",
        "    verbose=True\n",
        ")\n",
        "# 에이전트 실행\n",
        "agent_executor.run(\"고객 테이블에 대해서 설명해봐.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2lIKkHzWqEhq",
        "outputId": "d944f456-4d8b-4f48-ffc6-f359f4a11923"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mAction: list_tables_sql_db\n",
            "Action Input: \"\"\u001b[0m\n",
            "Observation: \u001b[38;5;200m\u001b[1;3mcustomer, actor, inventory, film_actor, rental, film_text, address, film, category, store, staff, country, language, city, film_category, payment\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I should query the schema of the film, rental, and customer tables.\n",
            "Action: schema_sql_db\n",
            "Action Input: \"film, rental, customer\"\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3m\n",
            "CREATE TABLE film (\n",
            "\tfilm_id INTEGER NOT NULL, \n",
            "\ttitle VARCHAR(255) NOT NULL, \n",
            "\tdescription TEXT DEFAULT NULL, \n",
            "\trelease_year VARCHAR(4) DEFAULT NULL, \n",
            "\tlanguage_id SMALLINT NOT NULL, \n",
            "\toriginal_language_id SMALLINT DEFAULT NULL, \n",
            "\trental_duration SMALLINT DEFAULT 3 NOT NULL, \n",
            "\trental_rate DECIMAL(4, 2) DEFAULT 4.99 NOT NULL, \n",
            "\tlength SMALLINT DEFAULT NULL, \n",
            "\treplacement_cost DECIMAL(5, 2) DEFAULT 19.99 NOT NULL, \n",
            "\trating VARCHAR(10) DEFAULT 'G', \n",
            "\tspecial_features VARCHAR(100) DEFAULT NULL, \n",
            "\tlast_update TIMESTAMP NOT NULL, \n",
            "\tPRIMARY KEY (film_id), \n",
            "\tCONSTRAINT fk_film_language FOREIGN KEY(language_id) REFERENCES language (language_id), \n",
            "\tCONSTRAINT fk_film_language_original FOREIGN KEY(original_language_id) REFERENCES language (language_id), \n",
            "\tCONSTRAINT \"CHECK_special_rating\" CHECK (rating in ('G','PG','PG-13','R','NC-17'))\n",
            ")\n",
            "\n",
            "/*\n",
            "3 rows from film table:\n",
            "film_id\ttitle\tdescription\trelease_year\tlanguage_id\toriginal_language_id\trental_duration\trental_rate\tlength\treplacement_cost\trating\tspecial_features\tlast_update\n",
            "1\tACADEMY DINOSAUR\tA Epic Drama of a Feminist And a Mad Scientist who must Battle a Teacher in The Canadian Rockies\t2006\t1\tNone\t6\t0.99\t86\t20.99\tPG\tDeleted Scenes,Behind the Scenes\t2021-03-06 15:52:00\n",
            "2\tACE GOLDFINGER\tA Astounding Epistle of a Database Administrator And a Explorer who must Find a Car in Ancient China\t2006\t1\tNone\t3\t4.99\t48\t12.99\tG\tTrailers,Deleted Scenes\t2021-03-06 15:52:00\n",
            "3\tADAPTATION HOLES\tA Astounding Reflection of a Lumberjack And a Car who must Sink a Lumberjack in A Baloon Factory\t2006\t1\tNone\t7\t2.99\t50\t18.99\tNC-17\tTrailers,Deleted Scenes\t2021-03-06 15:52:00\n",
            "*/\n",
            "\n",
            "\n",
            "CREATE TABLE customer (\n",
            "\tcustomer_id INTEGER NOT NULL, \n",
            "\tstore_id INTEGER NOT NULL, \n",
            "\tfirst_name VARCHAR(45) NOT NULL, \n",
            "\tlast_name VARCHAR(45) NOT NULL, \n",
            "\temail VARCHAR(50) DEFAULT NULL, \n",
            "\taddress_id INTEGER NOT NULL, \n",
            "\tactive CHAR(1) DEFAULT 'Y' NOT NULL, \n",
            "\tcreate_date TIMESTAMP NOT NULL, \n",
            "\tlast_update TIMESTAMP NOT NULL, \n",
            "\tPRIMARY KEY (customer_id), \n",
            "\tCONSTRAINT fk_customer_store FOREIGN KEY(store_id) REFERENCES store (store_id) ON UPDATE CASCADE, \n",
            "\tCONSTRAINT fk_customer_address FOREIGN KEY(address_id) REFERENCES address (address_id) ON UPDATE CASCADE\n",
            ")\n",
            "\n",
            "/*\n",
            "3 rows from customer table:\n",
            "customer_id\tstore_id\tfirst_name\tlast_name\temail\taddress_id\tactive\tcreate_date\tlast_update\n",
            "1\t1\tMARY\tSMITH\tMARY.SMITH@sakilacustomer.org\t5\t1\t2006-02-14 22:04:36\t2021-03-06 15:53:36\n",
            "2\t1\tPATRICIA\tJOHNSON\tPATRICIA.JOHNSON@sakilacustomer.org\t6\t1\t2006-02-14 22:04:36\t2021-03-06 15:53:36\n",
            "3\t1\tLINDA\tWILLIAMS\tLINDA.WILLIAMS@sakilacustomer.org\t7\t1\t2006-02-14 22:04:36\t2021-03-06 15:53:36\n",
            "*/\n",
            "\n",
            "\n",
            "CREATE TABLE rental (\n",
            "\trental_id INTEGER NOT NULL, \n",
            "\trental_date TIMESTAMP NOT NULL, \n",
            "\tinventory_id INTEGER NOT NULL, \n",
            "\tcustomer_id INTEGER NOT NULL, \n",
            "\treturn_date TIMESTAMP DEFAULT NULL, \n",
            "\tstaff_id SMALLINT NOT NULL, \n",
            "\tlast_update TIMESTAMP NOT NULL, \n",
            "\tPRIMARY KEY (rental_id), \n",
            "\tCONSTRAINT fk_rental_staff FOREIGN KEY(staff_id) REFERENCES staff (staff_id), \n",
            "\tCONSTRAINT fk_rental_inventory FOREIGN KEY(inventory_id) REFERENCES inventory (inventory_id), \n",
            "\tCONSTRAINT fk_rental_customer FOREIGN KEY(customer_id) REFERENCES customer (customer_id)\n",
            ")\n",
            "\n",
            "/*\n",
            "3 rows from rental table:\n",
            "rental_id\trental_date\tinventory_id\tcustomer_id\treturn_date\tstaff_id\tlast_update\n",
            "1\t2005-05-24 22:53:30\t367\t130\t2005-05-26 22:04:30\t1\t2021-03-06 15:53:41\n",
            "2\t2005-05-24 22:54:33\t1525\t459\t2005-05-28 19:40:33\t1\t2021-03-06 15:53:41\n",
            "3\t2005-05-24 23:03:39\t1711\t408\t2005-06-01 22:12:39\t1\t2021-03-06 15:53:41\n",
            "*/\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I should query the rental table to find the most rented films.\n",
            "Action: query_sql_db\n",
            "Action Input: \"SELECT film.title, COUNT(*) as num_rentals FROM rental INNER JOIN inventory ON rental.inventory_id = inventory.inventory_id INNER JOIN film ON inventory.film_id = film.film_id GROUP BY film.title ORDER BY num_rentals DESC LIMIT 10;\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m[('BUCKET BROTHERHOOD', 34), ('ROCKETEER MOTHER', 33), ('SCALAWAG DUCK', 32), ('RIDGEMONT SUBMARINE', 32), ('JUGGLER HARDLY', 32), ('GRIT CLOCKWORK', 32), ('FORWARD TEMPLE', 32), ('ZORRO ARK', 31), ('WIFE TURN', 31), ('TIMBERLAND SKY', 31)]\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
            "Final Answer: 가장 많이 빌린 영화는 'BUCKET BROTHERHOOD'입니다.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"가장 많이 빌린 영화는 'BUCKET BROTHERHOOD'입니다.\""
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent_executor.run(\"고객이 가장 많이 빌린 영화를 찾아줘.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
