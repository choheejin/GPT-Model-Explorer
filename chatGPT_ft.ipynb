{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L59ecD_6pKRu",
        "outputId": "f25536ea-09a8-4b43-a8f6-e6e19694e697"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터를 대화형 데이터로 전처리.\n",
        "\n",
        "import openpyxl\n",
        "import json\n",
        "\n",
        "excel_file_path = '/content/drive/My Drive/Colab-Notebooks/lab/data/original_QA.xlsx'\n",
        "jsonl_file_path = '/content/drive/My Drive/Colab-Notebooks/lab/data/output.jsonl'\n",
        "\n",
        "workbook = openpyxl.load_workbook(excel_file_path)\n",
        "sheet = workbook.active\n",
        "\n",
        "cnt = 0\n",
        "column_data = []\n",
        "for row in sheet.iter_rows(min_row=2, values_only=True):\n",
        "  if cnt == 30:\n",
        "    break\n",
        "  top_obj = {}\n",
        "  top_obj['messages'] = []\n",
        "  for i in range(0, 3):\n",
        "    obj = {}\n",
        "    if(i == 0):\n",
        "      obj['role'] = 'system'\n",
        "      obj['content'] = '너는 의학적 지식을 기반으로 질문에 대해 답하는 챗봇이야.'\n",
        "    elif(i == 1):\n",
        "      obj['role'] = 'user'\n",
        "      obj['content'] = str(row[2])\n",
        "    else:\n",
        "      obj['role'] = 'assistant'\n",
        "      obj['content'] = str(row[3])\n",
        "    top_obj['messages'].append(obj)\n",
        "  column_data.append(top_obj)\n",
        "  cnt += 1\n",
        "\n",
        "with open(jsonl_file_path, 'w', encoding='utf-8') as jsonlfile:\n",
        "    for item in column_data:\n",
        "        json.dump(item, jsonlfile, ensure_ascii=False)\n",
        "        jsonlfile.write('\\n')\n",
        "\n",
        "print(f' 열의 내용이 JSON 파일({jsonl_file_path})로 저장되었습니다.')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "010b66e4-14e5-4dd9-f963-8fa7ecd9284b",
        "id": "dTwzcZaUtfQO"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 열의 내용이 JSON 파일(/content/drive/My Drive/Colab-Notebooks/lab/data/output.jsonl)로 저장되었습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openpyxl\n",
        "import json\n",
        "\n",
        "excel_file_path = '/content/drive/My Drive/Colab-Notebooks/lab/data/original_QA.xlsx'\n",
        "jsonl_file_path = '/content/drive/My Drive/Colab-Notebooks/lab/data/output.jsonl'\n",
        "\n",
        "workbook = openpyxl.load_workbook(excel_file_path)\n",
        "sheet = workbook.active\n",
        "\n",
        "cnt = 0\n",
        "column_data = []\n",
        "for row in sheet.iter_rows(min_row=2, values_only=True):\n",
        "  obj = {}\n",
        "  if cnt == 30:\n",
        "    break\n",
        "  obj['prompt'] = str(row[2])\n",
        "  obj['completion'] = str(row[3])\n",
        "  column_data.append(obj)\n",
        "  cnt += 1\n",
        "\n",
        "with open(jsonl_file_path, 'w', encoding='utf-8') as jsonlfile:\n",
        "    for item in column_data:\n",
        "        json.dump(item, jsonlfile, ensure_ascii=False)\n",
        "        jsonlfile.write('\\n')\n",
        "\n",
        "print(f' 열의 내용이 JSON 파일({jsonl_file_path})로 저장되었습니다.')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fkNzqdE0p2PK",
        "outputId": "d7830064-dd9e-4c6d-cd35-535993e4cccb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 열의 내용이 JSON 파일(/content/drive/My Drive/Colab-Notebooks/lab/data/output.jsonl)로 저장되었습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bi8_WdgdBSNo",
        "outputId": "3f139213-ea9e-48df-d3e5-b31cbb0a0975"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2023.7.22)\n",
            "Installing collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### 데이터 셋이 잘 준비되었는지 확인한다.\n",
        "# We start by importing the required packages\n",
        "import json\n",
        "import os\n",
        "import tiktoken\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "\n",
        "# Next, we specify the data path and open the JSONL file\n",
        "\n",
        "data_path = \"/content/drive/My Drive/Colab-Notebooks/lab/data/output.jsonl\"\n",
        "\n",
        "# Load dataset\n",
        "with open(data_path) as f:\n",
        "    dataset = [json.loads(line) for line in f]\n",
        "\n",
        "# We can inspect the data quickly by checking the number of examples and the first item\n",
        "\n",
        "# Initial dataset stats\n",
        "print(\"Num examples:\", len(dataset))\n",
        "print(\"First example:\")\n",
        "for message in dataset[0][\"messages\"]:\n",
        "    print(message)\n",
        "\n",
        "# Now that we have a sense of the data, we need to go through all the different examples and check to make sure the formatting is correct and matches the Chat completions message structure\n",
        "\n",
        "# Format error checks\n",
        "format_errors = defaultdict(int)\n",
        "\n",
        "for ex in dataset:\n",
        "    if not isinstance(ex, dict):\n",
        "        format_errors[\"data_type\"] += 1\n",
        "        continue\n",
        "\n",
        "    messages = ex.get(\"messages\", None)\n",
        "    if not messages:\n",
        "        format_errors[\"missing_messages_list\"] += 1\n",
        "        continue\n",
        "\n",
        "    for message in messages:\n",
        "        if \"role\" not in message or \"content\" not in message:\n",
        "            format_errors[\"message_missing_key\"] += 1\n",
        "\n",
        "        if any(k not in (\"role\", \"content\", \"name\") for k in message):\n",
        "            format_errors[\"message_unrecognized_key\"] += 1\n",
        "\n",
        "        if message.get(\"role\", None) not in (\"system\", \"user\", \"assistant\"):\n",
        "            format_errors[\"unrecognized_role\"] += 1\n",
        "\n",
        "        content = message.get(\"content\", None)\n",
        "        if not content or not isinstance(content, str):\n",
        "            format_errors[\"missing_content\"] += 1\n",
        "\n",
        "    if not any(message.get(\"role\", None) == \"assistant\" for message in messages):\n",
        "        format_errors[\"example_missing_assistant_message\"] += 1\n",
        "\n",
        "if format_errors:\n",
        "    print(\"Found errors:\")\n",
        "    for k, v in format_errors.items():\n",
        "        print(f\"{k}: {v}\")\n",
        "else:\n",
        "    print(\"No errors found\")\n",
        "\n",
        "# Beyond the structure of the message, we also need to ensure that the length does not exceed the 4096 token limit.\n",
        "\n",
        "# Token counting functions\n",
        "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
        "\n",
        "# not exact!\n",
        "# simplified from https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb\n",
        "def num_tokens_from_messages(messages, tokens_per_message=3, tokens_per_name=1):\n",
        "    num_tokens = 0\n",
        "    for message in messages:\n",
        "        num_tokens += tokens_per_message\n",
        "        for key, value in message.items():\n",
        "            num_tokens += len(encoding.encode(value))\n",
        "            if key == \"name\":\n",
        "                num_tokens += tokens_per_name\n",
        "    num_tokens += 3\n",
        "    return num_tokens\n",
        "\n",
        "def num_assistant_tokens_from_messages(messages):\n",
        "    num_tokens = 0\n",
        "    for message in messages:\n",
        "        if message[\"role\"] == \"assistant\":\n",
        "            num_tokens += len(encoding.encode(message[\"content\"]))\n",
        "    return num_tokens\n",
        "\n",
        "def print_distribution(values, name):\n",
        "    print(f\"\\n#### Distribution of {name}:\")\n",
        "    print(f\"min / max: {min(values)}, {max(values)}\")\n",
        "    print(f\"mean / median: {np.mean(values)}, {np.median(values)}\")\n",
        "    print(f\"p5 / p95: {np.quantile(values, 0.1)}, {np.quantile(values, 0.9)}\")\n",
        "\n",
        "# Last, we can look at the results of the different formatting operations before proceeding with creating a fine-tuning job:\n",
        "\n",
        "# Warnings and tokens counts\n",
        "n_missing_system = 0\n",
        "n_missing_user = 0\n",
        "n_messages = []\n",
        "convo_lens = []\n",
        "assistant_message_lens = []\n",
        "\n",
        "for ex in dataset:\n",
        "    messages = ex[\"messages\"]\n",
        "    if not any(message[\"role\"] == \"system\" for message in messages):\n",
        "        n_missing_system += 1\n",
        "    if not any(message[\"role\"] == \"user\" for message in messages):\n",
        "        n_missing_user += 1\n",
        "    n_messages.append(len(messages))\n",
        "    convo_lens.append(num_tokens_from_messages(messages))\n",
        "    assistant_message_lens.append(num_assistant_tokens_from_messages(messages))\n",
        "\n",
        "print(\"Num examples missing system message:\", n_missing_system)\n",
        "print(\"Num examples missing user message:\", n_missing_user)\n",
        "print_distribution(n_messages, \"num_messages_per_example\")\n",
        "print_distribution(convo_lens, \"num_total_tokens_per_example\")\n",
        "print_distribution(assistant_message_lens, \"num_assistant_tokens_per_example\")\n",
        "n_too_long = sum(l > 4096 for l in convo_lens)\n",
        "print(f\"\\n{n_too_long} examples may be over the 4096 token limit, they will be truncated during fine-tuning\")\n",
        "\n",
        "# Pricing and default n_epochs estimate\n",
        "MAX_TOKENS_PER_EXAMPLE = 4096\n",
        "\n",
        "MIN_TARGET_EXAMPLES = 100\n",
        "MAX_TARGET_EXAMPLES = 25000\n",
        "TARGET_EPOCHS = 3\n",
        "MIN_EPOCHS = 1\n",
        "MAX_EPOCHS = 25\n",
        "\n",
        "n_epochs = TARGET_EPOCHS\n",
        "n_train_examples = len(dataset)\n",
        "if n_train_examples * TARGET_EPOCHS < MIN_TARGET_EXAMPLES:\n",
        "    n_epochs = min(MAX_EPOCHS, MIN_TARGET_EXAMPLES // n_train_examples)\n",
        "elif n_train_examples * TARGET_EPOCHS > MAX_TARGET_EXAMPLES:\n",
        "    n_epochs = max(MIN_EPOCHS, MAX_TARGET_EXAMPLES // n_train_examples)\n",
        "\n",
        "n_billing_tokens_in_dataset = sum(min(MAX_TOKENS_PER_EXAMPLE, length) for length in convo_lens)\n",
        "print(f\"Dataset has ~{n_billing_tokens_in_dataset} tokens that will be charged for during training\")\n",
        "print(f\"By default, you'll train for {n_epochs} epochs on this dataset\")\n",
        "print(f\"By default, you'll be charged for ~{n_epochs * n_billing_tokens_in_dataset} tokens\")\n",
        "print(\"See pricing page to estimate total costs\")"
      ],
      "metadata": {
        "id": "YCWo-WC0pQqN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f8d5db0-7e08-46a0-a196-2865cd75a661"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num examples: 30\n",
            "First example:\n",
            "{'role': 'system', 'content': '너는 의학적 지식을 기반으로 질문에 대해 답하는 챗봇이야.'}\n",
            "{'role': 'user', 'content': '전립선은 여성에도 있나요? '}\n",
            "{'role': 'assistant', 'content': '아닙니다. 전립선은 남성에게만 있는 생식기관 입니다'}\n",
            "No errors found\n",
            "Num examples missing system message: 0\n",
            "Num examples missing user message: 0\n",
            "\n",
            "#### Distribution of num_messages_per_example:\n",
            "min / max: 3, 3\n",
            "mean / median: 3.0, 3.0\n",
            "p5 / p95: 3.0, 3.0\n",
            "\n",
            "#### Distribution of num_total_tokens_per_example:\n",
            "min / max: 88, 300\n",
            "mean / median: 172.23333333333332, 170.5\n",
            "p5 / p95: 119.80000000000001, 228.0\n",
            "\n",
            "#### Distribution of num_assistant_tokens_per_example:\n",
            "min / max: 24, 225\n",
            "mean / median: 99.3, 93.5\n",
            "p5 / p95: 50.0, 158.10000000000002\n",
            "\n",
            "0 examples may be over the 4096 token limit, they will be truncated during fine-tuning\n",
            "Dataset has ~5167 tokens that will be charged for during training\n",
            "By default, you'll train for 3 epochs on this dataset\n",
            "By default, you'll be charged for ~15501 tokens\n",
            "See pricing page to estimate total costs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UjiTsPZupT1V",
        "outputId": "40cb6063-0d67-45ca-866c-56e3a6b21e00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (0.28.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import os\n",
        "\n",
        "openai.api_key = \"\"\n",
        "\n",
        "openai.File.create(\n",
        "  file=open(\"/content/drive/My Drive/Colab-Notebooks/lab/data/output.jsonl\", \"rb\"),\n",
        "  purpose='fine-tune'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QsDQSX6xOdw4",
        "outputId": "fea10881-332a-4a3f-bcc2-770cbcabe301"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<File file id=file-slSQA8hwXpAVSISwjbvdjEVq at 0x7beaa0164950> JSON: {\n",
              "  \"object\": \"file\",\n",
              "  \"id\": \"file-slSQA8hwXpAVSISwjbvdjEVq\",\n",
              "  \"purpose\": \"fine-tune\",\n",
              "  \"filename\": \"file\",\n",
              "  \"bytes\": 14878,\n",
              "  \"created_at\": 1693989096,\n",
              "  \"status\": \"uploaded\",\n",
              "  \"status_details\": null\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "openai.FineTuningJob.create(training_file=\"file-FaAlAHuBjyCI7s93UQ4qWdzV\", model=\"gpt-3.5-turbo-0613\", hyperparameters={\"n_epochs\":3})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkvTUeRlpM9v",
        "outputId": "95db5a7c-f057-4075-8eaa-34efaa3cc562"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<FineTuningJob fine_tuning.job id=ftjob-JNFXsKlYY3rwZ0fglne5oqP7 at 0x7f542b8a9df0> JSON: {\n",
              "  \"object\": \"fine_tuning.job\",\n",
              "  \"id\": \"ftjob-JNFXsKlYY3rwZ0fglne5oqP7\",\n",
              "  \"model\": \"gpt-3.5-turbo-0613\",\n",
              "  \"created_at\": 1693979314,\n",
              "  \"finished_at\": null,\n",
              "  \"fine_tuned_model\": null,\n",
              "  \"organization_id\": \"org-ySXADTYxkv77kxJzfGrXW0be\",\n",
              "  \"result_files\": [],\n",
              "  \"status\": \"created\",\n",
              "  \"validation_file\": null,\n",
              "  \"training_file\": \"file-FaAlAHuBjyCI7s93UQ4qWdzV\",\n",
              "  \"hyperparameters\": {\n",
              "    \"n_epochs\": 3\n",
              "  },\n",
              "  \"trained_tokens\": null\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "openai.FineTuningJob.create(training_file=\"file-FaAlAHuBjyCI7s93UQ4qWdzV\", model=\"gpt-3.5-turbo-0613\", hyperparameters={\"n_epochs\":5})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4C8_PtH6pMbw",
        "outputId": "da81ea19-ff0f-4f59-9a0f-24acd780358a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<FineTuningJob fine_tuning.job id=ftjob-tDuAUyaAdgrOYEk9K6cjFyFj at 0x7bea7f2a1a80> JSON: {\n",
              "  \"object\": \"fine_tuning.job\",\n",
              "  \"id\": \"ftjob-tDuAUyaAdgrOYEk9K6cjFyFj\",\n",
              "  \"model\": \"gpt-3.5-turbo-0613\",\n",
              "  \"created_at\": 1693989540,\n",
              "  \"finished_at\": null,\n",
              "  \"fine_tuned_model\": null,\n",
              "  \"organization_id\": \"org-ySXADTYxkv77kxJzfGrXW0be\",\n",
              "  \"result_files\": [],\n",
              "  \"status\": \"created\",\n",
              "  \"validation_file\": null,\n",
              "  \"training_file\": \"file-FaAlAHuBjyCI7s93UQ4qWdzV\",\n",
              "  \"hyperparameters\": {\n",
              "    \"n_epochs\": 5\n",
              "  },\n",
              "  \"trained_tokens\": null\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "openai.FineTuningJob.list(limit=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42IfRiVpC0QO",
        "outputId": "4de256a1-4d22-4e2e-e7be-a0e0e6fa8ac5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<OpenAIObject list at 0x7bea7f3bb150> JSON: {\n",
              "  \"object\": \"list\",\n",
              "  \"data\": [\n",
              "    {\n",
              "      \"object\": \"fine_tuning.job\",\n",
              "      \"id\": \"ftjob-tDuAUyaAdgrOYEk9K6cjFyFj\",\n",
              "      \"model\": \"gpt-3.5-turbo-0613\",\n",
              "      \"created_at\": 1693989540,\n",
              "      \"finished_at\": 1693990210,\n",
              "      \"fine_tuned_model\": \"ft:gpt-3.5-turbo-0613:personal::7viWhUBa\",\n",
              "      \"organization_id\": \"org-ySXADTYxkv77kxJzfGrXW0be\",\n",
              "      \"result_files\": [\n",
              "        \"file-7WG6zhoXS9f0miD7WGx2ma1k\"\n",
              "      ],\n",
              "      \"status\": \"succeeded\",\n",
              "      \"validation_file\": null,\n",
              "      \"training_file\": \"file-FaAlAHuBjyCI7s93UQ4qWdzV\",\n",
              "      \"hyperparameters\": {\n",
              "        \"n_epochs\": 5\n",
              "      },\n",
              "      \"trained_tokens\": 25535\n",
              "    },\n",
              "    {\n",
              "      \"object\": \"fine_tuning.job\",\n",
              "      \"id\": \"ftjob-JNFXsKlYY3rwZ0fglne5oqP7\",\n",
              "      \"model\": \"gpt-3.5-turbo-0613\",\n",
              "      \"created_at\": 1693979314,\n",
              "      \"finished_at\": 1693979983,\n",
              "      \"fine_tuned_model\": \"ft:gpt-3.5-turbo-0613:personal::7vfrjEpe\",\n",
              "      \"organization_id\": \"org-ySXADTYxkv77kxJzfGrXW0be\",\n",
              "      \"result_files\": [\n",
              "        \"file-UErpSMa7glOPcYV6J7R8stq8\"\n",
              "      ],\n",
              "      \"status\": \"succeeded\",\n",
              "      \"validation_file\": null,\n",
              "      \"training_file\": \"file-FaAlAHuBjyCI7s93UQ4qWdzV\",\n",
              "      \"hyperparameters\": {\n",
              "        \"n_epochs\": 3\n",
              "      },\n",
              "      \"trained_tokens\": 15321\n",
              "    },\n",
              "    {\n",
              "      \"object\": \"fine_tuning.job\",\n",
              "      \"id\": \"ftjob-BZgsjMC8x49lwyt3jifqht5d\",\n",
              "      \"model\": \"babbage-002\",\n",
              "      \"created_at\": 1693940453,\n",
              "      \"finished_at\": 1693940525,\n",
              "      \"fine_tuned_model\": \"ft:babbage-002:personal::7vVbKlAL\",\n",
              "      \"organization_id\": \"org-ySXADTYxkv77kxJzfGrXW0be\",\n",
              "      \"result_files\": [\n",
              "        \"file-uGL0TvQrxxs4lIRMj2uZsGZH\"\n",
              "      ],\n",
              "      \"status\": \"succeeded\",\n",
              "      \"validation_file\": null,\n",
              "      \"training_file\": \"file-QR5X5Fhf1sqb2jyuAq2zfr6z\",\n",
              "      \"hyperparameters\": {\n",
              "        \"n_epochs\": 3\n",
              "      },\n",
              "      \"trained_tokens\": 22995\n",
              "    }\n",
              "  ],\n",
              "  \"has_more\": false\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "openai.FineTuningJob.retrieve(\"ftjob-JNFXsKlYY3rwZ0fglne5oqP7\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgo-RQ1muETN",
        "outputId": "5d830fe1-42c8-4806-dcdd-84f54960d73b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<FineTuningJob fine_tuning.job id=ftjob-JNFXsKlYY3rwZ0fglne5oqP7 at 0x7f542ae02660> JSON: {\n",
              "  \"object\": \"fine_tuning.job\",\n",
              "  \"id\": \"ftjob-JNFXsKlYY3rwZ0fglne5oqP7\",\n",
              "  \"model\": \"gpt-3.5-turbo-0613\",\n",
              "  \"created_at\": 1693979314,\n",
              "  \"finished_at\": 1693979983,\n",
              "  \"fine_tuned_model\": \"ft:gpt-3.5-turbo-0613:personal::7vfrjEpe\",\n",
              "  \"organization_id\": \"org-ySXADTYxkv77kxJzfGrXW0be\",\n",
              "  \"result_files\": [\n",
              "    \"file-UErpSMa7glOPcYV6J7R8stq8\"\n",
              "  ],\n",
              "  \"status\": \"succeeded\",\n",
              "  \"validation_file\": null,\n",
              "  \"training_file\": \"file-FaAlAHuBjyCI7s93UQ4qWdzV\",\n",
              "  \"hyperparameters\": {\n",
              "    \"n_epochs\": 3\n",
              "  },\n",
              "  \"trained_tokens\": 15321\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 파인튜닝 작업 10개 나열\n",
        "openai.FineTuningJob.list(limit=10)\n",
        "\n",
        "# 파인튜닝 작업의 상태 검색\n",
        "openai.FineTuningJob.retrieve(\"ftjob-BZgsjMC8x49lwyt3jifqht5d\")\n",
        "\n",
        "# 작업 취소\n",
        "openai.FineTuningJob.cancel(\"ft-abc123\")\n",
        "\n",
        "# 파인튜닝 작업에서 최대 10개 이벤트 나열\n",
        "openai.FineTuningJob.list_events(id=\"ft-abc123\", limit=10)\n",
        "\n",
        "# 파인튜닝된 모델 삭제 (모델이 생성된 조직의 소유자여야 함)\n",
        "openai.Model.delete(\"ft-abc123\")"
      ],
      "metadata": {
        "id": "8UsN-llYqD5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai.FineTuningJob.list_events(id=\"ftjob-JNFXsKlYY3rwZ0fglne5oqP7\", limit=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXOeUCDWoSfW",
        "outputId": "cd224f64-4dfd-473e-c832-6197f01655e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<OpenAIObject list at 0x7bea7fffbb00> JSON: {\n",
              "  \"object\": \"list\",\n",
              "  \"data\": [\n",
              "    {\n",
              "      \"object\": \"fine_tuning.job.event\",\n",
              "      \"id\": \"ftevent-AkeuAhWXtfyK311hH653EFy0\",\n",
              "      \"created_at\": 1693979985,\n",
              "      \"level\": \"info\",\n",
              "      \"message\": \"Fine-tuning job successfully completed\",\n",
              "      \"data\": null,\n",
              "      \"type\": \"message\"\n",
              "    },\n",
              "    {\n",
              "      \"object\": \"fine_tuning.job.event\",\n",
              "      \"id\": \"ftevent-bdhuRZZ6IPwHKWg0pJV4JUix\",\n",
              "      \"created_at\": 1693979984,\n",
              "      \"level\": \"info\",\n",
              "      \"message\": \"New fine-tuned model created: ft:gpt-3.5-turbo-0613:personal::7vfrjEpe\",\n",
              "      \"data\": null,\n",
              "      \"type\": \"message\"\n",
              "    },\n",
              "    {\n",
              "      \"object\": \"fine_tuning.job.event\",\n",
              "      \"id\": \"ftevent-h8XhwM0tHoVFsehrXjSzRXq2\",\n",
              "      \"created_at\": 1693979977,\n",
              "      \"level\": \"info\",\n",
              "      \"message\": \"Step 90/90: training loss=0.59\",\n",
              "      \"data\": {\n",
              "        \"step\": 90,\n",
              "        \"train_loss\": 0.5945106744766235,\n",
              "        \"train_mean_token_accuracy\": 0.8571428656578064\n",
              "      },\n",
              "      \"type\": \"metrics\"\n",
              "    },\n",
              "    {\n",
              "      \"object\": \"fine_tuning.job.event\",\n",
              "      \"id\": \"ftevent-i8iDhMqloEkH3OffhKBCopWv\",\n",
              "      \"created_at\": 1693979975,\n",
              "      \"level\": \"info\",\n",
              "      \"message\": \"Step 89/90: training loss=1.11\",\n",
              "      \"data\": {\n",
              "        \"step\": 89,\n",
              "        \"train_loss\": 1.105747103691101,\n",
              "        \"train_mean_token_accuracy\": 0.6792452931404114\n",
              "      },\n",
              "      \"type\": \"metrics\"\n",
              "    },\n",
              "    {\n",
              "      \"object\": \"fine_tuning.job.event\",\n",
              "      \"id\": \"ftevent-YmtjnxKNj41BkbmbaTscRCvV\",\n",
              "      \"created_at\": 1693979972,\n",
              "      \"level\": \"info\",\n",
              "      \"message\": \"Step 88/90: training loss=0.61\",\n",
              "      \"data\": {\n",
              "        \"step\": 88,\n",
              "        \"train_loss\": 0.6068779230117798,\n",
              "        \"train_mean_token_accuracy\": 0.7983193397521973\n",
              "      },\n",
              "      \"type\": \"metrics\"\n",
              "    },\n",
              "    {\n",
              "      \"object\": \"fine_tuning.job.event\",\n",
              "      \"id\": \"ftevent-A2DUfTFSV8UAWvjxQnm26JgM\",\n",
              "      \"created_at\": 1693979970,\n",
              "      \"level\": \"info\",\n",
              "      \"message\": \"Step 87/90: training loss=0.48\",\n",
              "      \"data\": {\n",
              "        \"step\": 87,\n",
              "        \"train_loss\": 0.47572603821754456,\n",
              "        \"train_mean_token_accuracy\": 0.8461538553237915\n",
              "      },\n",
              "      \"type\": \"metrics\"\n",
              "    },\n",
              "    {\n",
              "      \"object\": \"fine_tuning.job.event\",\n",
              "      \"id\": \"ftevent-nQXYCyEPKKGdcBjR67vvByR1\",\n",
              "      \"created_at\": 1693979970,\n",
              "      \"level\": \"info\",\n",
              "      \"message\": \"Step 86/90: training loss=0.77\",\n",
              "      \"data\": {\n",
              "        \"step\": 86,\n",
              "        \"train_loss\": 0.7667502164840698,\n",
              "        \"train_mean_token_accuracy\": 0.7368420958518982\n",
              "      },\n",
              "      \"type\": \"metrics\"\n",
              "    },\n",
              "    {\n",
              "      \"object\": \"fine_tuning.job.event\",\n",
              "      \"id\": \"ftevent-8gzzbBnip98Ek0pYggQvVsJ1\",\n",
              "      \"created_at\": 1693979968,\n",
              "      \"level\": \"info\",\n",
              "      \"message\": \"Step 85/90: training loss=0.69\",\n",
              "      \"data\": {\n",
              "        \"step\": 85,\n",
              "        \"train_loss\": 0.6929259896278381,\n",
              "        \"train_mean_token_accuracy\": 0.7808219194412231\n",
              "      },\n",
              "      \"type\": \"metrics\"\n",
              "    },\n",
              "    {\n",
              "      \"object\": \"fine_tuning.job.event\",\n",
              "      \"id\": \"ftevent-lAUg7DpsHhgFC0TrKioWBp1G\",\n",
              "      \"created_at\": 1693979965,\n",
              "      \"level\": \"info\",\n",
              "      \"message\": \"Step 84/90: training loss=1.17\",\n",
              "      \"data\": {\n",
              "        \"step\": 84,\n",
              "        \"train_loss\": 1.173477053642273,\n",
              "        \"train_mean_token_accuracy\": 0.719298243522644\n",
              "      },\n",
              "      \"type\": \"metrics\"\n",
              "    },\n",
              "    {\n",
              "      \"object\": \"fine_tuning.job.event\",\n",
              "      \"id\": \"ftevent-5Sp5bxOYmbFqYElgtENOSTYe\",\n",
              "      \"created_at\": 1693979963,\n",
              "      \"level\": \"info\",\n",
              "      \"message\": \"Step 83/90: training loss=0.61\",\n",
              "      \"data\": {\n",
              "        \"step\": 83,\n",
              "        \"train_loss\": 0.6114791631698608,\n",
              "        \"train_mean_token_accuracy\": 0.8703703880310059\n",
              "      },\n",
              "      \"type\": \"metrics\"\n",
              "    }\n",
              "  ],\n",
              "  \"has_more\": true\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5에폭\n",
        "completion2 = openai.ChatCompletion.create(\n",
        "  model=\"ft:gpt-3.5-turbo-0613:personal::7viWhUBa\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"너는 의학적 지식을 기반으로 질문에 대해 답하는 챗봇이야.\"},\n",
        "    {\"role\": \"user\", \"content\": \"인종에 따른 전립선암의 발생의 차이에 대해서 알려주세요.\"}\n",
        "  ],\n",
        "  temperature=0.2,\n",
        "  max_tokens=256,\n",
        ")\n",
        "\n",
        "print(completion2.choices[0].message[\"content\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTSkzRxvsGTk",
        "outputId": "00beb078-d93e-4d7b-b723-26870eb6a75b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "한국과 비교하여 미국에서는 흑인인종에서 전립선암의 발생률이 백인인종에 비해 1.6배 정도 높게 나타나고 있습니다. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3에폭\n",
        "completion = openai.ChatCompletion.create(\n",
        "  model=\"ft:gpt-3.5-turbo-0613:personal::7vfrjEpe\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"너는 의학적 지식을 기반으로 질문에 대해 답하는 챗봇이야.\"},\n",
        "    {\"role\": \"user\", \"content\": \"인종에 따른 전립선암의 발생의 차이에 대해서 알려주세요.\"}\n",
        "  ],\n",
        "  temperature=0.2,\n",
        "  max_tokens=256,\n",
        ")\n",
        "\n",
        "print(completion.choices[0].message[\"content\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cprXvoTsFjfR",
        "outputId": "da6a9f30-3941-4368-83c6-7124a111e3a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "인종에 따른 전립선암의 발생률은 인종에 따라 차이가 있습니다. 전립선암은 서양인과 비교하여 아시아인에서는 낮은 발생률을 보이며, 흑인에서는 서양인에 비해 높은 발생률을 보입니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5에폭\n",
        "completion2 = openai.ChatCompletion.create(\n",
        "  model=\"ft:gpt-3.5-turbo-0613:personal::7viWhUBa\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"너는 의학적 지식을 기반으로 질문에 대해 답하는 챗봇이야.\"},\n",
        "    {\"role\": \"user\", \"content\": \"인종에 따른 전립선암의 발생의 차이에 대해서 알려주세요.\"}\n",
        "  ],\n",
        "  temperature=0.2,\n",
        "  max_tokens=256,\n",
        ")\n",
        "\n",
        "print(completion2.choices[0].message[\"content\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EtMFu0hItC_2",
        "outputId": "f66ffcc9-397b-4b59-a0dc-a73a23158f2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "한국에서는 전립선암의 발생률이 서구 국가에 비해 낮은 편이지만, 서구 국가에 비해 전립선암의 발생연령이 젊고, 발생률이 급격히 증가하고 있습니다. 특히, 한국인 남성에게 전립선암은 악성종양 중 가장 많이 발생하는 암으로 알려져 있습니다. 2020년 국가암등록통계에 따르면, 전립선암은 남성 암 발생의 9.6%를 차지하여, 1위 암으로 발생하였습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3에폭\n",
        "completion = openai.ChatCompletion.create(\n",
        "  model=\"ft:gpt-3.5-turbo-0613:personal::7vfrjEpe\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"너는 의학적 지식을 기반으로 질문에 대해 답하는 챗봇이야.\"},\n",
        "    {\"role\": \"user\", \"content\": \"사랑니 발치 후 주의사항에 대해서 알려줘.\"}\n",
        "  ],\n",
        "  temperature=0.2,\n",
        "  max_tokens=256,\n",
        ")\n",
        "\n",
        "print(completion.choices[0].message[\"content\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhlTt7NKtC2S",
        "outputId": "69d0f87a-5dd8-4b94-cfbc-dda141e40b3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "사랑니 발치 후에는 다음과 같은 주의사항을 지켜야 합니다.\n",
            "1. 출혈 : 수술 후 2~3시간 동안은 출혈이 심할 수 있으므로, 입안에 누는 거즈를 30분 동안 계속 누워 주세요.\n",
            "2. 통증 : 수술 후 2~3일 동안 통증이 심할 수 있으므로, 처방 받은 진통제를 규칙적으로 복용하세요.\n",
            "3. 종창 : 수술 후 2~3일 동안은 종창이 심할 수 있으므로, 냉찜질을 하거나 얼음을 입에 대지 마세요.\n",
            "4. 식사 : 수술 후 2~3일 동안은 고기류나 딱딱한 음식은 피하고, 액\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.ChatCompletion.create(\n",
        "  model=\"gpt-3.5-turbo-0613\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"너는 의학적 지식을 기반으로 질문에 대해 답하는 챗봇이야.\"},\n",
        "    {\"role\": \"user\", \"content\": \"사랑니 발치 후 주의사항에 대해서 알려줘.\"}\n",
        "  ],\n",
        "  temperature=0.2,\n",
        "  max_tokens=256,\n",
        ")\n",
        "print(response.choices[0].message[\"content\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvAihDbCGvs1",
        "outputId": "1028c3a4-ef4d-4104-9cf6-2f477ac477f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "사랑니 발치 후에는 몇 가지 주의사항을 지켜야 합니다. 다음은 일반적인 주의사항입니다:\n",
            "\n",
            "1. 충분한 휴식: 수술 후에는 몸을 휴식시키고 힘들게 하지 않는 것이 중요합니다. 수술 후 24시간 동안은 휴식을 취하고, 활동을 최소화해야 합니다.\n",
            "\n",
            "2. 통증 관리: 수술 후에는 통증이 발생할 수 있습니다. 의사가 처방한 통증 완화제를 규칙적으로 복용하고, 얼음 팩을 사용하여 통증을 완화시킬 수 있습니다.\n",
            "\n",
            "3. 혈액 응고: 수술 후에는 혈액 응고가 발생할 수 있으므로, 의사의 지시에 따라 혈전 예방을 위\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response3 = openai.Completion.create(\n",
        "  model=\"ft:babbage-002:personal::7vVbKlAL\",\n",
        "  prompt=\"인종에 따른 전립선암의 발생의 차이에 대해서 알려주세요.\",\n",
        "  max_tokens=256,\n",
        ")\n",
        "\n",
        "print(response3.choices[0].text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHaZbp6arGH4",
        "outputId": "1ce12dce-c491-40b9-abe7-c3d897791077"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 전립선암의 종사와 전립선암의 전기적 정책이 다르다고 하면, 전립선암의 독특성은 아래와 같습니다. 전립선암의 종사는 유전자전류, 유전자안전, 우정, 스테인레스 액체 등 다양한 전립선암질(정도촉진기 등)을 접목하여 발생합니다. 전립선암의 전기적 정책은 세폭기간에서 최대 2단계를 동시에 전립선암에서 갖춘 전력장애를 경험하고 진행합니다. 전립선암의 갖춘 전력장애는 70달이상 높습니다. 세폭기간에 7일 새로 인해 전립선암의 갖춘 전력은\n"
          ]
        }
      ]
    }
  ]
}